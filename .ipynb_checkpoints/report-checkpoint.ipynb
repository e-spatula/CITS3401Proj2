{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CITS3401 Project 2 Report\n",
    "## Eddie Atkinson (22487668)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of the previous exercise was to produce clean, aggregated data and load it into a database where it could be efficiently queried, manipulated and visualised. This component of the project is focused on analysing that data to discover useful and previous unknown trends and patterns using a variety of techniques, including association rule mining, classifcation, numerosity reduction, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning\n",
    "Data is stored in the database in normalised tables as part of its snowflake schema. In order to perform analytics on the data it is necessary to denormalise the data, remerging it into a central dataframe. The data used for this analysis is contained in the CSV files that were used to load the data in to database in the first place, however it is easy to imagine a situation where data would be exported in bulk from MSSQL to CSVs using the export wizard.   \n",
    "\n",
    "To start the data must be loaded into dataframes, remembering that the \"~\" separator was used on the data for ease of use in the SQL loading scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id  capital_gain  capital_loss  hours_pw\n",
      "0          0          2174             0        40\n",
      "1          1             0             0        38\n",
      "2          2             0             0        65\n",
      "3          3             0             0        37\n",
      "4          4             0             0        40\n",
      "   person_id  race_id  country_id  work_id  education_id  relationship_id  \\\n",
      "0          0        0           0        0             0                0   \n",
      "1          1        0           0        0             0                0   \n",
      "2          2        0           0        0             0                0   \n",
      "3          3        0           0        0             0                0   \n",
      "4          4        0           0        0             0                0   \n",
      "\n",
      "  gender income_bracket  age  \n",
      "0      M          <=50K   39  \n",
      "1      M          <=50K   37  \n",
      "2      F          <=50K   24  \n",
      "3      M          <=50K   32  \n",
      "4      M          <=50K   44  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dim_country = pd.read_csv(\"data/dim_country.csv\", sep=\"~\")\n",
    "dim_education = pd.read_csv(\"data/dim_education.csv\", sep=\"~\")\n",
    "dim_person = pd.read_csv(\"data/dim_person.csv\", sep=\"~\")\n",
    "dim_race = pd.read_csv(\"data/dim_race.csv\", sep=\"~\")\n",
    "dim_relationship = pd.read_csv(\"data/dim_relationship.csv\", sep=\"~\")\n",
    "dim_work = pd.read_csv(\"data/dim_work.csv\", sep=\"~\")\n",
    "fact_income = pd.read_csv(\"data/fact_income.csv\", sep=\"~\")\n",
    "\n",
    "# Have a look at some of the dataframes to check the reading was successful\n",
    "print(fact_income.head())\n",
    "print(dim_person.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demerge the data a central dataframe is incrementally constructed by merging the dataframes on their ID columns and then removing the ID columns from the data set. We'll start by constructing the central dataframe by merging ```dim_person``` with ```fact_income```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   capital_gain  capital_loss  hours_pw  race_id  country_id  work_id  \\\n",
      "0          2174             0        40        0           0        0   \n",
      "1             0             0        38        0           0        0   \n",
      "2             0             0        65        0           0        0   \n",
      "3             0             0        37        0           0        0   \n",
      "4             0             0        40        0           0        0   \n",
      "\n",
      "   education_id  relationship_id gender income_bracket  age  \n",
      "0             0                0      M          <=50K   39  \n",
      "1             0                0      M          <=50K   37  \n",
      "2             0                0      F          <=50K   24  \n",
      "3             0                0      M          <=50K   32  \n",
      "4             0                0      M          <=50K   44  \n"
     ]
    }
   ],
   "source": [
    "central_df = fact_income\n",
    "central_df = central_df.merge(dim_person, on=[\"person_id\"], how=\"left\")\n",
    "# Drop the person ID, it is no longer needed\n",
    "central_df.drop([\"person_id\"], axis=1, inplace=True)\n",
    "# Have a look at the dataframe to check all went well\n",
    "print(central_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that central, remerged dataframe has been created, the rest of the dimensions can be merged into it folllowing the same pattern of merging based on IDs followed by ID deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   capital_gain  capital_loss  hours_pw gender income_bracket  age  \\\n",
      "0          2174             0        40      M          <=50K   39   \n",
      "1             0             0        38      M          <=50K   37   \n",
      "2             0             0        65      F          <=50K   24   \n",
      "3             0             0        37      M          <=50K   32   \n",
      "4             0             0        40      M          <=50K   44   \n",
      "\n",
      "    country_name  education ethnicity relationship_role marital_relationship  \\\n",
      "0  United-States  Bachelors     White     Not-in-family        Never-married   \n",
      "1  United-States  Bachelors     White     Not-in-family        Never-married   \n",
      "2  United-States  Bachelors     White     Not-in-family        Never-married   \n",
      "3  United-States  Bachelors     White     Not-in-family        Never-married   \n",
      "4  United-States  Bachelors     White     Not-in-family        Never-married   \n",
      "\n",
      "  marriage_status work_class    occupation  \n",
      "0     Not Married  State-gov  Adm-clerical  \n",
      "1     Not Married  State-gov  Adm-clerical  \n",
      "2     Not Married  State-gov  Adm-clerical  \n",
      "3     Not Married  State-gov  Adm-clerical  \n",
      "4     Not Married  State-gov  Adm-clerical  \n"
     ]
    }
   ],
   "source": [
    "# Process dim_country\n",
    "central_df = central_df.merge(dim_country, on=[\"country_id\"], how=\"left\")\n",
    "# Delete country ID\n",
    "central_df.drop([\"country_id\"], axis=1, inplace=True)\n",
    "\n",
    "# Process dim_education\n",
    "central_df = central_df.merge(dim_education, on=[\"education_id\"], how=\"left\")\n",
    "# Delete education ID\n",
    "central_df.drop([\"education_id\"], axis=1, inplace=True)\n",
    "\n",
    "# Process dim_race\n",
    "central_df = central_df.merge(dim_race, on=[\"race_id\"], how=\"left\")\n",
    "central_df.drop([\"race_id\"], axis=1, inplace=True)\n",
    "\n",
    "# Process dim_relationship\n",
    "central_df = central_df.merge(dim_relationship, on=[\"relationship_id\"], how=\"left\")\n",
    "central_df.drop([\"relationship_id\"], axis=1, inplace=True)\n",
    "\n",
    "# Process dim_work\n",
    "central_df = central_df.merge(dim_work, on=[\"work_id\"], how=\"left\")\n",
    "central_df.drop([\"work_id\"], axis=1, inplace=True)\n",
    "\n",
    "# Take a final peek at the dataset to check that it's correct\n",
    "print(central_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been remerged we can perform analytics. Let's start with association rule mining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assocation Rule Mining\n",
    "\n",
    "Association rule mining is concerned with finding frequent itemsets. Association rule mining could be helpful in the context of this dataset for finding out which characteristics are associated with being in a higher income bracket, so that people wishing to increase their income can make data-driven decisions about how to do so. \n",
    "\n",
    "Whether an itemset is considered frequent is determined by its support - its relative frequency in the dataset. The minimum support required for an itemset to be considered frequent is highly problem and dataset specific, however it is common to specify a minimum support of 0.5 as a starting point and to tune the minimum support in order to identify meaningful association rules. \n",
    "\n",
    "However, it is not only the frequency of itemsets that is of interest for association rule mining, but also the interaction between itemsets in the data set. The interactions of itemsets are measured with two metrics - confidence and lift. Confidence measures the conditional probability of an itemset containing a particular item or parameter, given that another item or parameter is contained in the itemset. Lift measures the degree to which the presence of a particular item in an itemset increases the occurrence of another, taking into account the popularity of both items in the dataset. Lift is a better measure than confidence as confidence can reveal associations that exist only due to the popularity of one item in the itemset. \n",
    "\n",
    "The aim of this analysis is to uncover association rules between particular characteristics and income status, >=50K or <=50K using lift as a metric or if necessary, confidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
